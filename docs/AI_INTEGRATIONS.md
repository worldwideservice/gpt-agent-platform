# AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ - OpenRouter –∏ OpenAI

> –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å AI —Å–µ—Ä–≤–∏—Å–∞–º–∏ (OpenRouter, OpenAI GPT-5 Brain)
> 
> **–í–µ—Ä—Å–∏—è:** 1.1
> **–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:** 2025-02-18

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [OpenRouter –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è](#openrouter-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)
2. [OpenAI GPT-5 Brain](#openai-gpt-5-brain)
3. [Embeddings](#embeddings)
4. [Whisper (ASR)](#whisper-asr)
5. [TTS (Text-to-Speech)](#tts-text-to-speech)
6. [–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î](#–≤–µ–∫—Ç–æ—Ä–Ω–∞—è-–±–¥)
7. [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
8. [Product Analytics Hooks](#product-analytics-hooks)

---

## OpenRouter –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```typescript
// lib/services/ai/openrouter.client.ts

import { z } from 'zod'

const OpenRouterConfigSchema = z.object({
  apiKey: z.string().min(1),
  baseURL: z.string().url().default('https://openrouter.ai/api/v1'),
  defaultModel: z.string().default('openai/gpt-4o-mini'),
  embeddingModel: z.string().default('openai/text-embedding-3-large'),
})

export class OpenRouterClient {
  private apiKey: string
  private baseURL: string
  private defaultModel: string
  private embeddingModel: string

  constructor(config: z.infer<typeof OpenRouterConfigSchema>) {
    const validated = OpenRouterConfigSchema.parse(config)
    this.apiKey = validated.apiKey
    this.baseURL = validated.baseURL
    this.defaultModel = validated.defaultModel
    this.embeddingModel = validated.embeddingModel
  }

  async chat(messages: Array<{ role: string; content: string }>, options?: {
    model?: string
    temperature?: number
    maxTokens?: number
  }) {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
        'HTTP-Referer': process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000',
        'X-Title': 'GPT Agent AI Platform',
      },
      body: JSON.stringify({
        model: options?.model || this.defaultModel,
        messages,
        temperature: options?.temperature ?? 0.7,
        max_tokens: options?.maxTokens ?? 2048,
      }),
    })

    if (!response.ok) {
      const error = await response.text()
      throw new Error(`OpenRouter API error: ${response.status} ${error}`)
    }

    return await response.json()
  }

  async embeddings(text: string | string[]) {
    const texts = Array.isArray(text) ? text : [text]
    
    const response = await fetch(`${this.baseURL}/embeddings`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model: this.embeddingModel,
        input: texts,
      }),
    })

    if (!response.ok) {
      const error = await response.text()
      throw new Error(`OpenRouter Embeddings error: ${response.status} ${error}`)
    }

    return await response.json()
  }
}
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```typescript
import { OpenRouterClient } from '@/lib/services/ai/openrouter.client'

const client = new OpenRouterClient({
  apiKey: process.env.OPENROUTER_API_KEY!,
  defaultModel: 'openai/gpt-4o-mini',
  embeddingModel: 'openai/text-embedding-3-large',
})

// Chat completion
const response = await client.chat([
  { role: 'system', content: 'You are a helpful assistant.' },
  { role: 'user', content: 'Hello!' },
], {
  temperature: 0.7,
  maxTokens: 1000,
})

// Embeddings
const embeddings = await client.embeddings('Hello, world!')
```

---

## OpenAI GPT-5 Brain

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```typescript
// lib/services/ai/openai-brain.client.ts

import OpenAI from 'openai'

export interface BrainConfig {
  apiKey: string
  model?: string
  baseURL?: string
  customInstructions?: string
  tools?: Array<{
    type: 'function'
    function: {
      name: string
      description: string
      parameters: Record<string, any>
    }
  }>
}

export class OpenAIBrainClient {
  private client: OpenAI
  private model: string
  private customInstructions: string
  private tools: Array<any>

  constructor(config: BrainConfig) {
    this.client = new OpenAI({
      apiKey: config.apiKey,
      baseURL: config.baseURL || 'https://api.openai.com/v1',
    })
    this.model = config.model || 'gpt-5'
    this.customInstructions = config.customInstructions || ''
    this.tools = config.tools || []
  }

  async processCommand(
    command: string,
    context: {
      agentId?: string
      workspaceId?: string
      availableData?: Record<string, any>
    }
  ) {
    const systemPrompt = this.buildSystemPrompt(context)
    
    const response = await this.client.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: 'system',
          content: systemPrompt,
        },
        {
          role: 'user',
          content: command,
        },
      ],
      tools: this.tools.length > 0 ? this.tools : undefined,
      tool_choice: this.tools.length > 0 ? 'auto' : undefined,
      temperature: 0.7,
      max_tokens: 4000,
    })

    return response.choices[0].message
  }

  private buildSystemPrompt(context: {
    agentId?: string
    workspaceId?: string
    availableData?: Record<string, any>
  }): string {
    const parts: string[] = []

    if (this.customInstructions) {
      parts.push('## Custom Instructions\n')
      parts.push(this.customInstructions)
      parts.push('\n')
    }

    parts.push('## Available Context\n')
    parts.push(`Agent ID: ${context.agentId || 'N/A'}`)
    parts.push(`Workspace ID: ${context.workspaceId || 'N/A'}`)
    
    if (context.availableData) {
      parts.push('\n## Available Data\n')
      parts.push(JSON.stringify(context.availableData, null, 2))
    }

    parts.push('\n## Your Capabilities\n')
    parts.push('You can:')
    parts.push('- Create and modify automation rules')
    parts.push('- Analyze CRM data')
    parts.push('- Generate insights and recommendations')
    parts.push('- Process natural language commands')
    parts.push('- Understand context from knowledge base')

    return parts.join('\n')
  }

  async generateRule(
    description: string,
    context: {
      agentId: string
      workspaceId: string
      availableFields?: string[]
    }
  ) {
    const prompt = `Create an automation rule based on this description: "${description}"

Available fields: ${context.availableFields?.join(', ') || 'All fields'}

Return a JSON object with:
- name: string
- trigger_type: string
- conditions: array
- actions: array`

    const response = await this.processCommand(prompt, context)
    
    try {
      return JSON.parse(response.content || '{}')
    } catch {
      throw new Error('Failed to parse rule from AI response')
    }
  }
}
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```typescript
import { OpenAIBrainClient } from '@/lib/services/ai/openai-brain.client'

const brain = new OpenAIBrainClient({
  apiKey: process.env.OPENAI_API_KEY!,
  model: 'gpt-5',
  customInstructions: 'You are the AI Brain of GPT Agent platform...',
  tools: [
    {
      type: 'function',
      function: {
        name: 'create_rule',
        description: 'Create an automation rule',
        parameters: {
          type: 'object',
          properties: {
            name: { type: 'string' },
            trigger_type: { type: 'string' },
            conditions: { type: 'array' },
            actions: { type: 'array' },
          },
        },
      },
    },
  ],
})

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã
const result = await brain.processCommand(
  '–°–æ–∑–¥–∞–π –ø—Ä–∞–≤–∏–ª–æ: –µ—Å–ª–∏ —Å–¥–µ–ª–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", –æ—Ç–ø—Ä–∞–≤—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ',
  {
    agentId: 'agent-123',
    workspaceId: 'workspace-456',
  }
)

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª–∞
const rule = await brain.generateRule(
  '–û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ —á–µ—Ä–µ–∑ 3 –¥–Ω—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å–¥–µ–ª–∫–∏',
  {
    agentId: 'agent-123',
    workspaceId: 'workspace-456',
    availableFields: ['name', 'status', 'created_at'],
  }
)
```

---

## Embeddings

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```typescript
// lib/services/ai/embeddings.service.ts

import { OpenRouterClient } from './openrouter.client'

export class EmbeddingsService {
  private client: OpenRouterClient

  constructor(client: OpenRouterClient) {
    this.client = client
  }

  async generateEmbedding(text: string): Promise<number[]> {
    const response = await this.client.embeddings(text)
    return response.data[0].embedding
  }

  async generateEmbeddings(texts: string[]): Promise<number[][]> {
    const response = await this.client.embeddings(texts)
    return response.data.map(item => item.embedding)
  }

  chunkText(text: string, chunkSize = 600, overlap = 120): string[] {
    const words = text.split(/\s+/)
    const chunks: string[] = []

    for (let start = 0; start < words.length; start += chunkSize - overlap) {
      const end = Math.min(words.length, start + chunkSize)
      const slice = words.slice(start, end).join(' ').trim()

      if (slice.length > 0) {
        chunks.push(slice)
      }

      if (end === words.length) break
    }

    return chunks
  }

  async processDocument(
    content: string,
    metadata: Record<string, any> = {}
  ): Promise<Array<{ content: string; embedding: number[]; metadata: Record<string, any> }>> {
    const chunks = this.chunkText(content)
    const embeddings = await this.generateEmbeddings(chunks)

    return chunks.map((chunk, index) => ({
      content: chunk,
      embedding: embeddings[index],
      metadata: {
        ...metadata,
        chunkIndex: index,
        totalChunks: chunks.length,
      },
    }))
  }
}
```

---

## Whisper (ASR)

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```typescript
// lib/services/ai/whisper.service.ts

import OpenAI from 'openai'

export class WhisperService {
  private client: OpenAI

  constructor(apiKey: string) {
    this.client = new OpenAI({ apiKey })
  }

  async transcribe(audioFile: File | Buffer, options?: {
    language?: string
    prompt?: string
    responseFormat?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt'
  }): Promise<string> {
    const file = audioFile instanceof File 
      ? new File([audioFile], audioFile.name, { type: audioFile.type })
      : new File([audioFile], 'audio.mp3', { type: 'audio/mpeg' })

    const transcription = await this.client.audio.transcriptions.create({
      file,
      model: 'whisper-1',
      language: options?.language,
      prompt: options?.prompt,
      response_format: options?.responseFormat || 'text',
    })

    return typeof transcription === 'string' 
      ? transcription 
      : transcription.text
  }
}
```

---

## TTS (Text-to-Speech)

### ElevenLabs

```typescript
// lib/services/ai/tts-elevenlabs.service.ts

export class ElevenLabsTTS {
  private apiKey: string
  private voiceId: string

  constructor(apiKey: string, voiceId: string) {
    this.apiKey = apiKey
    this.voiceId = voiceId
  }

  async synthesize(text: string, options?: {
    voiceId?: string
    modelId?: string
    stability?: number
    similarityBoost?: number
  }): Promise<Buffer> {
    const response = await fetch(
      `https://api.elevenlabs.io/v1/text-to-speech/${options?.voiceId || this.voiceId}`,
      {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': this.apiKey,
        },
        body: JSON.stringify({
          text,
          model_id: options?.modelId || 'eleven_multilingual_v2',
          voice_settings: {
            stability: options?.stability ?? 0.5,
            similarity_boost: options?.similarityBoost ?? 0.5,
          },
        }),
      }
    )

    if (!response.ok) {
      throw new Error(`ElevenLabs TTS error: ${response.status}`)
    }

    return Buffer.from(await response.arrayBuffer())
  }
}
```

### Azure TTS

```typescript
// lib/services/ai/tts-azure.service.ts

export class AzureTTS {
  private apiKey: string
  private region: string

  constructor(apiKey: string, region: string) {
    this.apiKey = apiKey
    this.region = region
  }

  async synthesize(text: string, options?: {
    voice?: string
    language?: string
  }): Promise<Buffer> {
    const token = await this.getAccessToken()
    
    const response = await fetch(
      `https://${this.region}.tts.speech.microsoft.com/cognitiveservices/v1`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
        },
        body: this.buildSSML(text, options),
      }
    )

    if (!response.ok) {
      throw new Error(`Azure TTS error: ${response.status}`)
    }

    return Buffer.from(await response.arrayBuffer())
  }

  private async getAccessToken(): Promise<string> {
    const response = await fetch(
      `https://${this.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`,
      {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': this.apiKey,
        },
      }
    )

    return await response.text()
  }

  private buildSSML(text: string, options?: { voice?: string; language?: string }): string {
    const voice = options?.voice || 'ru-RU-DmitryNeural'
    const language = options?.language || 'ru-RU'
    
    return `<speak version='1.0' xml:lang='${language}'>
      <voice xml:lang='${language}' name='${voice}'>
        ${text}
      </voice>
    </speak>`
  }
}
```

---

## –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î

### pgvector (Supabase)

```typescript
// lib/services/ai/vector.service.ts

import { getSupabaseServiceRoleClient } from '@/lib/supabase/admin'

export class VectorService {
  private supabase = getSupabaseServiceRoleClient()

  async storeEmbedding(
    orgId: string,
    agentId: string | null,
    content: string,
    embedding: number[],
    metadata: Record<string, any> = {}
  ) {
    const { data, error } = await this.supabase
      .from('knowledge_chunks')
      .insert({
        org_id: orgId,
        agent_id: agentId,
        content,
        embedding: `[${embedding.join(',')}]`,
        metadata,
      })
      .select()
      .single()

    if (error) throw error
    return data
  }

  async searchSimilar(
    orgId: string,
    queryEmbedding: number[],
    options?: {
      agentId?: string
      articleId?: string
      limit?: number
      threshold?: number
    }
  ) {
    const { data, error } = await this.supabase.rpc('match_knowledge_chunks', {
      query_embedding: `[${queryEmbedding.join(',')}]`,
      org_uuid: orgId,
      agent_uuid: options?.agentId || null,
      article_uuid: options?.articleId || null,
      match_count: options?.limit || 5,
      similarity_threshold: options?.threshold || 0.3,
    })

    if (error) throw error
    return data
  }
}
```

---

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –¥–æ–∫—É–º–µ–Ω—Ç ‚Üí embeddings ‚Üí –ø–æ–∏—Å–∫

```typescript
import { OpenRouterClient } from '@/lib/services/ai/openrouter.client'
import { EmbeddingsService } from '@/lib/services/ai/embeddings.service'
import { VectorService } from '@/lib/services/ai/vector.service'

// 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
const openRouter = new OpenRouterClient({
  apiKey: process.env.OPENROUTER_API_KEY!,
})
const embeddings = new EmbeddingsService(openRouter)
const vector = new VectorService()

// 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
const document = '–í–∞—à —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞...'
const processed = await embeddings.processDocument(document, {
  source: 'article-123',
  title: '–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏',
})

// 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
for (const chunk of processed) {
  await vector.storeEmbedding(
    'workspace-456',
    'agent-123',
    chunk.content,
    chunk.embedding,
    chunk.metadata
  )
}

// 4. –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
const query = '–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è'
const queryEmbedding = await embeddings.generateEmbedding(query)
const results = await vector.searchSimilar(
  'workspace-456',
  queryEmbedding,
  {
    agentId: 'agent-123',
    limit: 5,
    threshold: 0.3,
  }
)
```

---

## Product Analytics Hooks

- **–ö–æ–º–ø–æ–Ω–µ–Ω—Ç**: `components/providers/ProductAnalyticsProvider.tsx`.
- **–ö–æ–Ω—Ç–µ–∫—Å—Ç—ã**: `public` (–º–∞—Ä–∫–µ—Ç–∏–Ω–≥) –∏ `app` (–∫–∞–±–∏–Ω–µ—Ç) ‚Äî –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ `context` –ø—Ä–æ–ø—Å.
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã**: Segment (`AnalyticsBrowser`) –∏ PostHog (`posthog-js`).
- **–°–æ–±—ã—Ç–∏—è**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç `page`/`$pageview` —Å –ø—Ä–æ–ø–µ—Ä—Ç—è–º–∏ `url` –∏ `context`.
- **–ü–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è**: –¥–æ–±–∞–≤–∏—Ç—å `identify`, `group`, —Å–æ–±—ã—Ç–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å release-notes –∞–ª–µ—Ä—Ç–∞–º–∏.

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-01-26  
**–í–µ—Ä—Å–∏—è:** 1.1

